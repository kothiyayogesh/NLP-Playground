# multilingual_bot
Bot which can handle a defined set of languages

# Problem Statement
Build a bot which is able to take a valid set of languages as input and answer them accordingly.

# Solution Approach

## Embedding Vectors
We know that embedding verctors are used to represent words and sentences which can store their syntax and semantics i.e. words and their context. It is well accepted that if two words or sentences have same meaning or are being used in same context then their embedding vectors should be similar and if plotted in a vector space or feature map they should lie in the same neighbourhood.
This notion suits well for single language, but what about words and sentences in two different languages.

**Since the bot messages are usually sentences from now on _embedding vectors_ will stand for _sentence embedding vectors_.**

If we think about the basic idea why embedding vectors are used, it will be clear that if any two or more sentences, no matter what language they are, in have same meaning then their vectors should be similar.
Following this idea people at facebook have devised a model to generate embedding vectors for sentences in any language. No, they have not created separate models for each language but **one** single model for all languages (*93 to be exact*).

## LSAER (Language Agnostic SEntence Representation)
Their work has been documented [here](https://arxiv.org/abs/1812.10464) and you can find a generalised description [here](https://code.fb.com/ai-research/laser-multilingual-sentence-embeddings/).

> I am giving a brief description of what they made and how they made. For simplicity lot of details have been left out. Refer to the above mentioned links for in depth knowledge.

### Architecture
The LASER is a combination of an **encoder** and a **decoder**. Encoder is a *5-layer BiLSTM* model precedded by *BPE encoder*.
It has a vocabulary of BPE codes for all 93 languages. Decoder is a *single layer LSTM* model precedded by embedding obtained by encoder concatenated with BPE encoding of the sentence and a language ID and followed by a *softmax* layer.

### Training
First a set of two languages is choosen and a parallel corpus is created containing 1000 sentences in each language.
The input language sentence (*marked as **A***) is fed to the encoder. At first layer the BPE embedding is calculated and fed to the following LSTM cells in both forward and backward direction.

> I am assuming that the reader has basic knowledge of how BiLSTM model works. If not, then first read some prescribed text about those.

After 5 such layers a *maxpooling* layer is used to get a embedding of size 1024. This embedding is now fed to the decoder, where it is concatenated with the BPE encoding of target language (*marked as **B***). The decoder generates a sentence which is supposed to be in target language. A language ID is passed to the decoder along with the embedding vetors.
This training is done for a defined set of languages.

### Final Sentene Embedding
Once the training is complete the embedding of size 1024 generated by the encoder becomes the required sentence embedding vector for the given sentence. Now if sentence in any language along with the language id is provided the trained encoder will generate the embedding vectors.

## Bot Training
Now as we can represent sentences of different languages in same vector space, we can say that whether or not two sentences of different languages are similar. 

### How to get embedding vectors of a sentence.
The exact method of getting sentence vector is mentioned [here](https://github.com/facebookresearch/LASER/tree/master/tasks/embed).

For simplicity I am giving a steps to do the same.
- Install LASER
- Set environment variable by using this command `export LASER=/path/to/laser/`
- Store the sentences in a *.txt* file.
- use this command to get embedding `bash /path/to/LASER/tasks/embed/embed.sh /path/to/INPUT_FILE/ LANGUAGE /path/to/OUTPUT_FILE`

**There might be some errors so be ready to solve them.**

In the provided link there is a way given how to read the *.raw* file to get embedding.
